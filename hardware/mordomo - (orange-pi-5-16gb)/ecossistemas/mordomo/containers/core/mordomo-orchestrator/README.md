# Mordomo Orchestrator

## ğŸ¯ VisÃ£o Geral
O **Mordomo Orchestrator** unifica a execuÃ§Ã£o fÃ­sica do sistema para otimizar recursos no Orange Pi 5, mas mantÃ©m a **separaÃ§Ã£o lÃ³gica** de responsabilidades em dois mÃ³dulos internos distintos:

1.  **Session Controller (antigo Conversation Manager)**: Gerencia a "forma" da interaÃ§Ã£o (estado da voz, turn-taking, interrupÃ§Ãµes).
2.  **System Core (antigo Core API)**: Gerencia o "conteÃºdo" (LLM, ferramentas, banco de dados, integraÃ§Ãµes).

## ğŸš€ MÃ³dulos Internos

### 1. Session Controller (Gerente de SessÃ£o)
ResponsÃ¡vel pela fluidez da interaÃ§Ã£o de voz.
-   **MÃ¡quina de Estados**: Controla se o robÃ´ estÃ¡ `OUVINDO`, `PENSANDO` ou `FALANDO`.
-   **GestÃ£o de InterrupÃ§Ã£o**: Se o usuÃ¡rio falar enquanto o robÃ´ fala, este mÃ³dulo envia o sinal de `STOP` para o TTS imediatamente.
-   **IdentificaÃ§Ã£o**: MantÃ©m o `speaker_id` ativo na sessÃ£o.

### 2. System Core (CÃ©rebro Executivo)
ResponsÃ¡vel pela inteligÃªncia e execuÃ§Ã£o.
-   **Semantic Cache**: Intercepta inputs antes do LLM para comandos frequentes.
-   **LLM Gateway (LiteLLM)**: Gerencia chamadas para modelos de IA.
    -   **EstratÃ©gia**: API First (OpenAI/Anthropic/Groq) -> Fallback Local.
    -   **Modelo Local**: `qwen2.5:1.5b` (Leve e rÃ¡pido para fallback).
-   **Action Dispatcher**: Sistema universal de roteamento para mÃ³dulos externos.
-   **Skills Client**: Interface para delegar execuÃ§Ã£o de cÃ³digo Python.
    -   **NÃ­vel 1 (TÃ¡tico):** Envia scripts rÃ¡pidos para o `skills-runner` (ex: cotaÃ§Ã£o, cÃ¡lculos).
    -   **NÃ­vel 2 (EstratÃ©gico):** Envia intenÃ§Ãµes complexas para o MÃ³dulo RPA (ex: projetos de scraping).
-   **Event System**: Processa notificaÃ§Ãµes assÃ­ncronas dos mÃ³dulos com fila de prioridade.
-   **Event Memory**: Armazena histÃ³rico de eventos para consultas contextuais do LLM.
    -   Permite perguntas como: _"Quem me mandou mensagem hÃ¡ 10 minutos?"_
    -   _"Sobre o que estÃ¡vamos falando quanto aos RPAs?"_
-   **API REST**: Serve o Dashboard e Apps externos.

## ğŸ”„ Dois Fluxos de ComunicaÃ§Ã£o

### A. Request-Reply (Mordomo â†’ MÃ³dulos)
**Fluxo iniciado pelo usuÃ¡rio ou LLM.**
```
UsuÃ¡rio: "Ligar luz da sala"
  â†“
LLM interpreta â†’ {"module": "iot", "action": "turn_on", "params": {"device": "luz_sala"}}
  â†“
Action Dispatcher consulta Consul â†’ Valida aÃ§Ã£o â†’ Publica NATS (iot.command)
  â†“
MÃ³dulo IoT executa â†’ Responde via NATS (iot.response)
  â†“
Dispatcher retorna resultado â†’ TTS: "Luz da sala ligada"
```

### B. Event-Driven (MÃ³dulos â†’ Mordomo)
**Fluxo iniciado por eventos externos.**
```
CÃ¢mera detecta intruso
  â†“
MÃ³dulo Security publica evento â†’ security.event.intrusion_detected (priority=CRITICAL)
  â†“
Event Queue enfileira com prioridade mÃ¡xima
  â†“
Event Handler executa automaticamente:
  1. Liga todas as luzes (via Action Dispatcher)
  2. Toca sirene
  3. Envia notificaÃ§Ã£o push
  4. TTS: "Intruso detectado!"
```

## ğŸ§  Arquitetura do Semantic Cache

O Semantic Cache Ã© um mÃ³dulo interno projetado para "curto-circuitar" o fluxo de processamento, evitando chamadas caras e lentas ao LLM para comandos triviais.

### Fluxo de Processamento
```mermaid
graph TD
    A[STT Input] --> B(Mordomo Orchestrator)
    B --> C{Semantic Cache?}
    C -- Hit (>0.95) --> D[Executa AÃ§Ã£o Mapeada]
    C -- Miss --> E[LLM / Brain]
    E --> F[Interpreta IntenÃ§Ã£o]
    F --> G[Executa AÃ§Ã£o]
    G --> H[Atualiza Cache]
```

### Stack TecnolÃ³gica do Cache
-   **Modelo de Embeddings**: `all-MiniLM-L6-v2` (Quantizado INT8).
    -   Tamanho: ~20MB.
    -   Velocidade: < 10ms em CPU (Orange Pi 5).
-   **Vector Store**: FAISS (Facebook AI Similarity Search) em modo in-memory ou Qdrant (modo embedded).
-   **PersistÃªncia**: SQLite (para mapeamento Vector ID -> AÃ§Ã£o JSON).

## ğŸ” Sistema de PermissÃµes e SeguranÃ§a (Herdado)

O Orchestrator implementa o sistema de permissÃµes hierÃ¡rquico anteriormente definido no Conversation Manager.

### NÃ­veis de Acesso
- **NÃ­vel 0 (PÃºblico)**: Clima, MÃºsica, Perguntas Gerais.
- **NÃ­vel 3 (Residente)**: IluminaÃ§Ã£o (cÃ´modo atual).
- **NÃ­vel 5 (FamÃ­lia)**: Termostatos, CÃ¢meras (visualizaÃ§Ã£o).
- **NÃ­vel 8 (Admin/Pais)**: Alarmes, AutomaÃ§Ãµes, Fechaduras.
- **NÃ­vel 10 (Root)**: Scripts, GestÃ£o de UsuÃ¡rios, ConfiguraÃ§Ã£o do Sistema.

### Fluxo de VerificaÃ§Ã£o
1.  **IdentificaÃ§Ã£o**: O `speaker_id` vem do mÃ³dulo de DiarizaÃ§Ã£o.
2.  **VerificaÃ§Ã£o de SessÃ£o**: Se a sessÃ£o foi iniciada por um Admin, mas uma voz desconhecida ou de nÃ­vel inferior tenta um comando crÃ­tico, o sistema bloqueia (PrevenÃ§Ã£o de EscalaÃ§Ã£o de PrivilÃ©gio).
3.  **ValidaÃ§Ã£o de MÃ³dulo**: Verifica se o usuÃ¡rio tem nÃ­vel suficiente para o mÃ³dulo solicitado (ex: `lights`, `alarm`).

## ğŸ—„ï¸ Modelo de Dados Unificado (PostgreSQL)

O schema do banco de dados unifica as necessidades de sessÃ£o e histÃ³rico.

```prisma
model User {
  user_id         String    @id @db.VarChar(50)
  name            String    @db.VarChar(100)
  level           Int       @default(0)
  is_guest        Boolean   @default(false)
  allowed_modules String[]  // Para convidados restritos
  conversations   Conversation[]
  action_logs     ActionLog[]
}

model Conversation {
  id         String    @id @default(uuid())
  speaker_id String    @db.VarChar(50)
  started_at DateTime  @default(now())
  status     Status    @default(ACTIVE) // ACTIVE, COMPLETED, INTERRUPTED
  messages   Message[]
}

model Message {
  id              String   @id @default(uuid())
  conversation_id String
  role            Role     // USER, ASSISTANT, SYSTEM
  content         String   @db.Text
  timestamp       DateTime @default(now())
}

model ActionLog {
  id            Int      @id @default(autoincrement())
  user_id       String
  action        String
  allowed       Boolean
  denial_reason String?
  timestamp     DateTime @default(now())
}
```

## ğŸ”Œ Interfaces e API

### NATS Topics (Event Driven)
-   `mordomo.speech.transcribed`: Entrada de texto do STT.
-   `mordomo.brain.process_request`: (Interno) Solicita processamento LLM.
-   `mordomo.tts.generate_request`: SaÃ­da para sÃ­ntese de voz.
-   `iot.command.*`: Comandos para dispositivos.

### REST API (Dashboard)
-   `GET /api/v1/conversations`: HistÃ³rico de conversas.
-   `POST /api/v1/users`: GestÃ£o de usuÃ¡rios.
-   `GET /api/v1/status`: SaÃºde do sistema.

## ğŸ› ï¸ Stack TÃ©cnica do Container

-   **Linguagem**: Python 3.11+ (FastAPI).
-   **Servidor**: Uvicorn (com `uvloop` para performance).
-   **ComunicaÃ§Ã£o**: `nats-py` (Cliente NATS assÃ­ncrono).
-   **Banco de Dados**: ConexÃ£o direta com PostgreSQL (TimescaleDB) para logs e Qdrant para vetores.

## ğŸ“Š Estimativa de Recursos

| Componente | RAM Estimada | CPU (MÃ©dia) |
| :--- | :--- | :--- |
| Core (FastAPI + Logic) | 120MB | 5% |
| Semantic Cache (Model + Index) | 150MB | 10% (pico) |
| Action Dispatcher + Event Queue | 50MB | 3% |
| NATS & DB Connectors | 30MB | 2% |
| **TOTAL** | **~350MB** | **~20%** |

> **Comparativo**: A soluÃ§Ã£o anterior (`conversation-manager` + `mordomo-core-api`) consumia ~500MB combinados. A unificaÃ§Ã£o economiza ~150MB de RAM e reduz latÃªncia de comunicaÃ§Ã£o interna.

## ğŸ“ Estrutura de Pastas

```
mordomo-orchestrator/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ api/                          # Endpoints REST/WebSocket
â”‚   â”œâ”€â”€ core/
â”‚   â”‚   â”œâ”€â”€ cache/
â”‚   â”‚   â”‚   â””â”€â”€ semantic_cache.py     # Cache vetorial (FAISS)
â”‚   â”‚   â”œâ”€â”€ context/                  # Gerenciador de Contexto de Conversa
â”‚   â”‚   â”œâ”€â”€ dispatcher/
â”‚   â”‚   â”‚   â”œâ”€â”€ service_discovery.py  # IntegraÃ§Ã£o Consul
â”‚   â”‚   â”‚   â”œâ”€â”€ action_dispatcher.py  # Request-Reply pattern
â”‚   â”‚   â”‚   â””â”€â”€ README.md
â”‚   â”‚   â”œâ”€â”€ events/
â”‚   â”‚   â”‚   â”œâ”€â”€ event_queue.py        # Fila de prioridade
â”‚   â”‚   â”‚   â”œâ”€â”€ event_memory.py       # âœ¨ NOVO: Armazena eventos para consultas LLM
â”‚   â”‚   â”‚   â”œâ”€â”€ handlers.py           # PolÃ­ticas de reaÃ§Ã£o a eventos
â”‚   â”‚   â”‚   â”œâ”€â”€ README.md
â”‚   â”‚   â”‚   â””â”€â”€ EVENT_MEMORY.md       # âœ¨ DocumentaÃ§Ã£o completa
â”‚   â”‚   â””â”€â”€ llm/
â”‚   â”‚       â””â”€â”€ service.py            # LiteLLM (Cloud + Fallback)
â”‚   â”œâ”€â”€ models/                       # Pydantic Models
â”‚   â””â”€â”€ services/                     # ServiÃ§os auxiliares
â”œâ”€â”€ config/
â”œâ”€â”€ tests/
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ requirements.txt
â””â”€â”€ main.py
```

## ğŸ§  Event Memory - Consultas Contextuais

### PropÃ³sito
Permite que o usuÃ¡rio faÃ§a perguntas sobre eventos recentes, como:
- _"Quem me mandou mensagem no WhatsApp hÃ¡ 10 minutos?"_
- _"Sobre o que estÃ¡vamos falando quanto aos RPAs?"_
- _"Qual foi a Ãºltima encomenda entregue?"_

### Como Funciona
1. **Armazenamento AutomÃ¡tico**: Todos os eventos processados sÃ£o salvos na Event Memory com metadados completos
2. **IndexaÃ§Ã£o MÃºltipla**: Eventos indexados por mÃ³dulo, tipo e timestamp para busca rÃ¡pida
3. **API REST**: LLM consulta via `/api/events/context?query=...` para obter contexto
4. **Contexto Formatado**: Event Memory retorna texto estruturado pronto para injetar no prompt do LLM

### Exemplo de Fluxo
```
UsuÃ¡rio: "Aslam, quem me mandou mensagem hÃ¡ 10 minutos?"
  â†“
STT â†’ Orchestrator â†’ LLM detecta query sobre evento passado
  â†“
LLM: GET /api/events/context?query=quem me mandou mensagem hÃ¡ 10 minutos
  â†“
Event Memory retorna:
  "1. [15:30] mensagens.message_received
   De: JoÃ£o Silva (whatsapp)
   Mensagem: Confirma reuniÃ£o amanhÃ£?"
  â†“
LLM responde: "Foi o JoÃ£o Silva, ele perguntou sobre a reuniÃ£o de amanhÃ£"
  â†“
TTS: SÃ­ntese de voz
```

### API Endpoints
```http
# Eventos recentes (filtro flexÃ­vel)
GET /api/events/recent?minutes=30&module=mensagens

# Contexto formatado para LLM
GET /api/events/context?query=quem me mandou mensagem hÃ¡ 10 minutos

# EstatÃ­sticas
GET /api/events/stats
```

### Estrutura de Evento Armazenado
```json
{
  "timestamp": "2025-12-04T15:30:00Z",
  "module": "mensagens",
  "event_type": "message_received",
  "priority": "HIGH",
  "data": {
    "sender": "JoÃ£o Silva",
    "platform": "whatsapp",
    "preview": "Confirma reuniÃ£o amanhÃ£?"
  },
  "handler_response": "Avisei sobre mensagem de JoÃ£o Silva"
}
```

### ConfiguraÃ§Ã£o
- **Capacidade**: 500 eventos (FIFO circular)
- **RetenÃ§Ã£o**: 24 horas (cleanup automÃ¡tico)
- **RAM**: ~5-10MB (500 eventos)
- **LatÃªncia**: <5ms para consultas tÃ­picas

ğŸ“– **DocumentaÃ§Ã£o completa**: [EVENT_MEMORY.md](src/core/events/EVENT_MEMORY.md)

---

## âœ… Status de ImplementaÃ§Ã£o

- âœ… **Action Dispatcher**: Sistema universal de roteamento com Service Discovery (Consul)
- âœ… **Event System**: Fila de prioridade para notificaÃ§Ãµes assÃ­ncronas de mÃ³dulos
- âœ… **Event Memory**: Armazena eventos recentes para consultas contextuais do LLM
- âœ… **Event Handlers**: PolÃ­ticas automÃ¡ticas (intruso, mensagens, temperatura, etc.)
- âœ… **LLM Service**: LiteLLM com fallback Cloud â†’ Local (qwen2.5:1.5b)
- âœ… **Semantic Cache**: FAISS para bypass de LLM em comandos frequentes
- â³ **Session Controller**: MÃ¡quina de estados de conversaÃ§Ã£o (a implementar)
- â³ **REST API**: Endpoints para Dashboard UI (parcialmente implementado)
- â³ **PostgreSQL Integration**: PersistÃªncia de conversas e logs (a implementar)

## ğŸ”Œ IntegraÃ§Ãµes NATS

### Subscriptions (Escuta)
- `*.event.>`: Todos os eventos de mÃ³dulos externos (wildcard)
- `*.response`: Respostas de comandos despachados
- `mordomo.speech.transcribed`: Texto do STT (a implementar)

### Publications (Publica)
- `{module}.command`: Comandos para mÃ³dulos (via Action Dispatcher)
- `tts.generate_request`: SolicitaÃ§Ã£o de sÃ­ntese de voz (a implementar)
- `system.orchestrator.status`: Heartbeat e status (a implementar)
