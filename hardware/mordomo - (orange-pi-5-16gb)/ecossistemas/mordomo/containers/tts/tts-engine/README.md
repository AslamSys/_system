# ğŸ”Š TTS Engine

**Container:** `tts-engine`  
**Ecossistema:** Mordomo  
**Protocolo:** NATS (Infraestrutura) + FastAPI (HTTP/REST)

---

## ğŸ“‹ PropÃ³sito

Sintetizar respostas do Brain em Ã¡udio natural PT-BR, com suporte a streaming e baixa latÃªncia.

---

## ğŸ¯ Responsabilidades

- âœ… Receber texto do Core API/Brain via NATS
- âœ… Sintetizar Ã¡udio em streaming (chunks)
- âœ… **InterrompÃ­vel**: Para sÃ­ntese quando usuÃ¡rio fala
- âœ… Baixa latÃªncia (<500ms)
- âœ… Voz natural em portuguÃªs brasileiro
- âœ… Fallback offline quando Azure indisponÃ­vel
- âœ… Suporte a mÃºltiplos speakers simultÃ¢neos

---

## ğŸ”§ Engines TTS

**Linguagem:** Python (FastAPI)

**Por que Python?** LatÃªncia dominada por Azure API (200ms) ou Piper model (100ms). Overhead Python (<5ms) desprezÃ­vel no contexto total.

### PrimÃ¡rio: **Piper TTS (Local)**
- **Modelo PadrÃ£o**: `pt_BR-faber-medium.onnx`
- **LatÃªncia**: ~100ms (no Orange Pi 5)
- **Vantagem**: Resposta instantÃ¢nea, privacidade total, zero custo.
- **Specs**: 22050 Hz, Mono.

### SecundÃ¡rio: **Azure Cognitive Services (Cloud)**
- **Uso**: Textos longos (> 200 caracteres) ou fallback.
- **Voz**: pt-BR-DonatoNeural
- **LatÃªncia**: ~300ms + Network
- **Custo**: Free Tier (500k chars/mÃªs)

---

## ğŸ“Š EspecificaÃ§Ãµes

```yaml
Piper Audio (PadrÃ£o):
  Sample Rate: 22050 Hz
  Channels: 1 (mono)
  Format: PCM 16-bit
  Bitrate: 44.1 kbps

Azure Audio (Long-form):
  Sample Rate: 16000 Hz
  Channels: 1 (mono)
  Format: PCM 16-bit
  Codec: RIFF WAV

Performance:
  LatÃªncia Piper: ~100ms (InstantÃ¢neo)
  LatÃªncia Azure: ~300ms
```

---

## ğŸ“¥ InstalaÃ§Ã£o dos Modelos

Para usar o Piper, vocÃª precisa baixar o modelo `faber` e seu config JSON para a pasta de modelos:

```bash
mkdir -p models
cd models
# Baixar Modelo
wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx
# Baixar Config
wget https://huggingface.co/rhasspy/piper-voices/resolve/v1.0.0/pt/pt_BR/faber/medium/pt_BR-faber-medium.onnx.json
```

---

## ğŸ”Œ Interfaces

### Input (NATS)

**1. RequisiÃ§Ãµes de SÃ­ntese**
```python
subject: "tts.generate.{speaker_id}"
payload: {
  "text": "A temperatura atual Ã© 23 graus",
  "speaker_id": "user_1",
  "engine": "azure",  # azure | piper (opcional)
  "voice": "donato",  # nome da voz (opcional)
  "gender": "masculino"  # masculino | feminino (opcional)
}
```

**2. Comandos de InterrupÃ§Ã£o**
```python
subject: "tts.interrupt.{speaker_id}"
payload: {}  # Vazio, apenas trigger

# Enviado por: STT quando detecta voz do usuÃ¡rio
# Efeito: Para sÃ­ntese imediatamente, descarta buffer
```

### Output (NATS)

**1. Chunks de Ãudio**
```python
subject: "tts.audio_chunk.{speaker_id}"
payload: {
  "data": "<base64 PCM>",  # Ãudio codificado em base64
  "chunk_index": 0,
  "is_final": false,  # true no Ãºltimo chunk
  "timestamp": 1732723200.123,
  "engine": "azure"
}
```

**2. Status da SÃ­ntese**
```python
subject: "tts.status.{speaker_id}"
payload: {
  "status": "started",  # started | completed | interrupted | error
  "speaker_id": "user_1",
  "engine": "azure",
  "timestamp": 1732723200.123,
  
  # Campos adicionais conforme status:
  "chunks_sent": 42,  # quando completed
  "error": "...",  # quando error
}

# Status possÃ­veis:
# - started: SÃ­ntese iniciada
# - completed: SÃ­ntese finalizada com sucesso
# - interrupted: UsuÃ¡rio interrompeu (comeÃ§ou a falar)
# - error: Erro na sÃ­ntese
```

### HTTP API (Testes/Desenvolvimento)
```http
POST /synthesize
{
  "text": "OlÃ¡, mundo!",
  "engine": "azure",  # opcional
  "streaming": true
}

GET /health
# Retorna engines disponÃ­veis e status

POST /test-latency
# Testa latÃªncia de uma engine especÃ­fica
```

---

## âš™ï¸ ConfiguraÃ§Ã£o (.env)

```bash
# Server
HOST=0.0.0.0
PORT=8007

# Azure TTS (PrimÃ¡rio)
AZURE_SPEECH_KEY1=your_key_here
AZURE_SPEECH_KEY2=your_backup_key
AZURE_SPEECH_REGION=brazilsouth

# Default Engine
TTS_ENGINE=azure  # azure | piper

# NATS (Infraestrutura)
NATS_URL=nats://localhost:4222

# Audio Settings
SAMPLE_RATE=22050
CHANNELS=1
BIT_DEPTH=16
CHUNK_SIZE=4096
```

---

## ğŸ”„ Fluxo de Processamento

### SÃ­ntese Normal (Sem InterrupÃ§Ã£o)
```mermaid
graph LR
    A[Brain via NATS] --> B[TTS Engine]
    B --> C{Engine?}
    C -->|Azure| D[Azure Speech API]
    C -->|Piper| E[Piper Local]
    D --> F[Audio Stream]
    E --> F
    F --> G[Chunks via NATS]
    G --> H[Audio Player]
```

### SÃ­ntese com InterrupÃ§Ã£o
```mermaid
graph LR
    A[TTS gerando Ã¡udio] --> B{UsuÃ¡rio falou?}
    B -->|NÃ£o| C[Continua sÃ­ntese]
    B -->|Sim| D[STT detecta voz]
    D --> E[Publica tts.interrupt.*]
    E --> F[TTS para imediatamente]
    F --> G[Publica status interrupted]
    C --> H[PrÃ³ximo chunk]
    H --> B
```

### Processamento Detalhado
```python
async def synthesize_text(text: str, speaker_id: str):
    # 1. Receber requisiÃ§Ã£o via NATS (tts.generate.{speaker_id})
    
    # 2. Selecionar engine (Azure primÃ¡rio, Piper fallback)
    engine = tts_engines.get("azure") or tts_engines.get("piper")
    
    # 3. Marcar inÃ­cio de sÃ­ntese
    await interruption_manager.start_synthesis(speaker_id)
    
    # 4. Publicar status "started"
    await nats.publish(f"tts.status.{speaker_id}", {"status": "started"})
    
    # 5. Sintetizar em streaming com verificaÃ§Ã£o de interrupÃ§Ã£o
    chunk_index = 0
    async for chunk in engine.synthesize_stream(text):
        # Verificar se usuÃ¡rio interrompeu
        if await interruption_manager.is_interrupted(speaker_id):
            logger.info("Synthesis interrupted by user")
            break
        
        # Publicar chunk no NATS
        await nats.publish(
            f"tts.audio_chunk.{speaker_id}",
            {
                "data": base64.b64encode(chunk).decode(),
                "chunk_index": chunk_index,
                "is_final": False
            }
        )
        chunk_index += 1
    
    # 6. Verificar se completou ou foi interrompido
    if not interrupted:
        # Marcar chunk final
        await nats.publish(
            f"tts.audio_chunk.{speaker_id}",
            {"chunk_index": chunk_index, "is_final": True}
        )
        
        # Publicar status "completed"
        await nats.publish(
            f"tts.status.{speaker_id}",
            {"status": "completed", "chunks_sent": chunk_index}
        )
    
    # 7. Limpar recursos
    await interruption_manager.end_synthesis(speaker_id)
```

### Exemplo de InterrupÃ§Ã£o
```python
# Timeline de uma conversa:

# t=0ms: Brain envia texto para TTS
â†’ tts.generate.user_1 {"text": "A temperatura estÃ¡..."}

# t=50ms: TTS inicia sÃ­ntese
â†’ tts.status.user_1 {"status": "started"}

# t=150ms: Primeiro chunk de Ã¡udio
â†’ tts.audio_chunk.user_1 {"data": "...", "chunk_index": 0}

# t=300ms: UsuÃ¡rio comeÃ§a a falar
â†’ STT detecta voz do usuÃ¡rio

# t=310ms: STT envia comando de interrupÃ§Ã£o
â†’ tts.interrupt.user_1 {}

# t=315ms: TTS para sÃ­ntese
â†’ tts.status.user_1 {"status": "interrupted"}

# Resultado: Mordomo para de falar imediatamente
```

---

## ğŸ¨ Vozes Azure DisponÃ­veis

Lista de vozes mais rÃ¡pidas documentada nesta seÃ§Ã£o.

**Top 5 Mais RÃ¡pidas:**
1. Francisca (F) - 212ms
2. Yara (F) - 253ms
3. **Donato (M) - 291ms** â­ PADRÃƒO
4. Valerio (M) - 297ms
5. Humberto (M) - 305ms

---

## ğŸ“¦ DependÃªncias

```txt
# Core
fastapi==0.104.1
uvicorn[standard]==0.24.0
python-dotenv==1.0.0
pydantic==2.5.0

# TTS Engines
azure-cognitiveservices-speech==1.47.0  # PrimÃ¡rio
piper-tts==1.2.0  # Fallback offline

# Event Bus
nats-py==2.6.0

# Testing
pytest==7.4.3
httpx==0.25.2
```

---

## ğŸ³ Docker

```dockerfile
FROM python:3.11-slim

WORKDIR /app

# Install dependencies
COPY requirements.txt .
RUN pip install --no-cache-dir -r requirements.txt

# Download Piper voice model (fallback)
RUN python -c "from piper import PiperVoice; \
    PiperVoice.load('pt_BR-faber-medium')"

# Copy application
COPY . .

EXPOSE 8007

CMD ["python", "main.py"]
```

---

## ğŸ“ˆ MÃ©tricas

```python
# SÃ­nteses
tts_synthesis_total{engine, speaker_id}
tts_characters_synthesized_total{engine}

# Performance
tts_latency_ms{engine}  # LatÃªncia total
tts_first_chunk_ms{engine}  # Tempo atÃ© primeiro chunk

# Engines
tts_engine_health{engine}  # 0=down, 1=up
tts_fallback_activations_total  # Quantas vezes caiu para Piper
```

---

## ğŸš€ Uso

```bash
# Instalar dependÃªncias
pip install -r requirements.txt

# Configurar .env
cp .env.example .env
# Editar AZURE_SPEECH_KEY1, AZURE_SPEECH_REGION

# Iniciar servidor
python main.py

# Testar API
curl -X POST http://localhost:8007/synthesize \
  -H "Content-Type: application/json" \
  -d '{"text": "OlÃ¡, mundo!", "engine": "azure"}'
```

---

## ğŸ” Troubleshooting

**Azure nÃ£o funciona:**
- Verificar keys no .env
- Confirmar region=brazilsouth
- Testar: `curl https://{region}.api.cognitive.microsoft.com/sts/v1.0/issuetoken`

**Piper nÃ£o encontra modelo:**
- Executar: `python -c "from piper import PiperVoice; PiperVoice.load('pt_BR-faber-medium')"`
- Modelo serÃ¡ baixado em `~/.local/share/piper-voices/`

**LatÃªncia alta:**
- Azure: Trocar voz (Francisca 212ms, Donato 291ms)
- Piper: Sempre ~108ms
- Network: Verificar latÃªncia para Azure Brasil South

---

*Ãšltima atualizaÃ§Ã£o: Dezembro 2025 - Testes completos Azure + Piper*
