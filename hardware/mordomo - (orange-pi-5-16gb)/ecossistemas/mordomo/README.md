# ğŸ  Ecossistema Mordomo (Aslam)

> ğŸ“ **NavegaÃ§Ã£o:** [ğŸ  InÃ­cio](../../../../README.md) > [ğŸ”§ Hardware](../../../README.md) > [ğŸ¯ Mordomo](../../README.md) > [ğŸŒ Ecossistemas](../README.md) > [ğŸ  Mordomo](README.md)

Sistema principal de assistente de voz inteligente multiusuÃ¡rio com processamento completo de Ã¡udio, reconhecimento de fala, LLM local/cloud e sÃ­ntese de voz.

---

## ğŸ“ Estrutura de Ambientes

```
ecossistemas/mordomo/containers/
â”‚
â”œâ”€ ğŸ¤ stt/                          (6 containers - Speech-to-Text)
â”‚  â”œâ”€ audio-capture-vad/           âœ… Implementado
â”‚  â”œâ”€ wake-word-detector/          âœ… Implementado
â”‚  â”œâ”€ speaker-verification/        âœ… Implementado
â”‚  â”œâ”€ whisper-asr/                 âœ… Implementado
â”‚  â”œâ”€ speaker-id-diarization/      â³ Em desenvolvimento
â”‚  â””â”€ source-separation/           â³ Pendente
â”‚
â”œâ”€ ğŸ”Š tts/                          (2 containers - Text-to-Speech)
â”‚  â”œâ”€ tts-engine/                  âœ… Implementado
â”‚  â””â”€ audio-bridge/                âœ… Especificado (Rust)
â”‚
â”œâ”€ ğŸ¤– openclaw/                     (1 container - OpenClaw Agent)
â”‚  â””â”€ openclaw-agent               â³ Especificado (Gateway + Browser RPA + Skills + NATS Bridge)
â”‚
â””â”€ ğŸ§  core/                         (5 containers - OrquestraÃ§Ã£o + Brain)
   â”œâ”€ mordomo-orchestrator/        âœ… Implementado (Session + LLM + Dispatcher + Events + Cache)
   â”œâ”€ skills-runner/               â³ Especificado (Python Sandbox)
   â”œâ”€ mordomo-brain/               â³ Pendente (RAG + Advanced reasoning)
   â”œâ”€ system-watchdog/             âœ… Implementado (DEFCON + Thermal protection)
   â”œâ”€ core-gateway/                â³ Pendente
   â””â”€ dashboard-ui/                â³ Pendente (Canvas A2UI)

Total: 14 containers | Implementados: 7/14 (50%)

NOTAS:
- action-dispatcher foi integrado ao mordomo-orchestrator
- ComunicaÃ§Ã£o/RPA integrados via OpenClaw Agent (1 container, substitui 2 hardwares separados)
- OpenClaw tem 4 mÃ³dulos internos (gateway, browser-rpa, skills-hub, brain-bridge) rodando em 1 container
```

**ğŸ“– DocumentaÃ§Ã£o por Ambiente:**
- [ğŸ¤ STT - Speech-to-Text](./containers/stt/README.md)
- [ğŸ”Š TTS - Text-to-Speech](./containers/tts/README.md)
- [ğŸ¤– OpenClaw Agent - ComunicaÃ§Ã£o + RPA](./containers/openclaw/README.md)
- [ğŸ§  CORE - OrquestraÃ§Ã£o + Brain](./containers/core/README.md)

---

## VisÃ£o Geral

O **Mordomo** Ã© o ecossistema central do projeto Aslam. ResponsÃ¡vel por toda a interaÃ§Ã£o de voz com os usuÃ¡rios, desde a captura de Ã¡udio atÃ© a resposta sintetizada.

### CaracterÃ­sticas Principais

- âœ… AtivaÃ§Ã£o via **wake word** ("ASLAM")
- âœ… **MultiusuÃ¡rio** com contextos separados por falante
- âœ… **LLM local-first** (Ollama) com fallback cloud
- âœ… DetecÃ§Ã£o de **interrupÃ§Ãµes** e sobreposiÃ§Ã£o de fala
- âœ… **TTS pausÃ¡vel** e streaming de baixa latÃªncia
- âœ… **Speaker Verification** (apenas usuÃ¡rios autorizados)
- âœ… Interface em **tablet/dashboard** web
- âœ… **Processamento paralelo** (latÃªncia otimizada ~500ms)

---

## Arquitetura por Ambientes (14 containers)

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ECOSSISTEMA MORDOMO                      â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                             â”‚
â”‚  ğŸ¤ AMBIENTE STT (6 containers)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ Audio Capture VAD â†’ Wake Word â†’ Whisper ASR          â”‚  â”‚
â”‚  â”‚                           â†“                           â”‚  â”‚
â”‚  â”‚ Speaker Verification â†’ Speaker ID/Diarization        â”‚  â”‚
â”‚  â”‚                           â†“                           â”‚  â”‚
â”‚  â”‚                   Source Separation (condicional)     â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                 â”‚
â”‚                           â†“ speech.diarized                 â”‚
â”‚                                                             â”‚
  ğŸ§  AMBIENTE CORE (6 containers)                            â”‚
  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
  â”‚ Mordomo Orchestrator (Unificado)                      â”‚  â”‚
  â”‚   â”œâ”€ Session Controller                               â”‚  â”‚
  â”‚   â”œâ”€ LLM Service (Cloud + Local Fallback)            â”‚  â”‚
  â”‚   â”œâ”€ Semantic Cache (FAISS)                          â”‚  â”‚
  â”‚   â”œâ”€ Action Dispatcher (Consul + NATS)               â”‚  â”‚
  â”‚   â””â”€ Event System (Priority Queue + Handlers)        â”‚  â”‚
  â”‚        â†“                                â†“             â”‚  â”‚
  â”‚ Skills Runner (Python Sandbox) â† Orchestrator        â”‚  â”‚
  â”‚        â†“                                â†“             â”‚  â”‚
  â”‚ Brain (RAG) â† Core Gateway â† Dashboard UI            â”‚  â”‚
  â”‚                                                       â”‚  â”‚
  â”‚ System Watchdog (DEFCON + Thermal Control)           â”‚  â”‚
  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                           â”‚                                 â”‚
â”‚                           â†“ tts.generate                    â”‚
â”‚                                                             â”‚
â”‚  ğŸ”Š AMBIENTE TTS (2 containers)                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚ TTS Engine (Azure/Piper) â†’ Audio Bridge               â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â”‚                                                             â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

Estrutura de DiretÃ³rios:
containers/
â”œâ”€ stt/       (Speech-to-Text)
â”œâ”€ tts/       (Text-to-Speech)
â”œâ”€ core/      (OrquestraÃ§Ã£o + Brain)
â””â”€ openclaw/  (OpenClaw Agent - ComunicaÃ§Ã£o + RPA)
```

---

## ğŸ”„ Ciclo de Vida do Gate (ParalelizaÃ§Ã£o)

```
1. wake_word.detected
   â†“
   [GATE FECHA] â†’ Processamento paralelo inicia
   â”œâ”€ Speaker Verification (200ms)
   â”œâ”€ Whisper ASR (buffering)
   â””â”€ Speaker ID (buffering)
   
2. speaker.verified âœ…
   â†“
   [GATE ABRE] â†’ Libera resultados downstream
   
3. conversation.ended
   â†“
   [GATE RESETA] â†’ Todos voltam ao IDLE
   â”œâ”€ Buffers limpos
   â”œâ”€ Contextos descartados
   â””â”€ Pronto para prÃ³xima detecÃ§Ã£o
```

**LatÃªncia:** ~500ms atÃ© primeira transcriÃ§Ã£o (vs ~1000ms sequencial)

---

## ğŸ” Sistema de PermissÃµes (NÃ­veis)

**Arquitetura:**
```
Speaker Verification:  WHO (quem Ã©?)
       â†“
Conversation Manager:  CAN (pode fazer?)
       â†“
Action Dispatcher:     DO (executa)
```

### NÃ­veis de Acesso

```yaml
NÃ­vel 0-2: GUEST (convidados)
  âœ… Consultar clima, hora, notÃ­cias
  âœ… Tocar mÃºsica
  âŒ Controlar dispositivos
  âŒ Ver cÃ¢meras
  âŒ Executar scripts

NÃ­vel 3-5: USER (usuÃ¡rios comuns)
  âœ… Tudo do GUEST +
  âœ… Controlar luzes/AC prÃ³prios cÃ´modos
  âœ… Ver cÃ¢meras Ã¡reas comuns
  âŒ Desligar alarme
  âŒ Criar automaÃ§Ãµes

NÃ­vel 6-8: POWER_USER (famÃ­lia)
  âœ… Tudo do USER +
  âœ… Controlar todos dispositivos
  âœ… Ver todas cÃ¢meras
  âœ… Criar automaÃ§Ãµes simples
  âŒ Modificar configuraÃ§Ãµes sistema
  âŒ Adicionar/remover usuÃ¡rios

NÃ­vel 9-10: ADMIN (administrador)
  âœ… Acesso total irrestrito
  âœ… Gerenciar usuÃ¡rios
  âœ… Configurar sistema
  âœ… Executar scripts Python/shell
```

### GestÃ£o de UsuÃ¡rios

**UsuÃ¡rios Permanentes:**
- Cadastrados no PostgreSQL via Conversation Manager
- Voz registrada no Speaker Verification
- NÃ­vel de acesso fixo

**Convidados TemporÃ¡rios:**
- Criados via API com expiraÃ§Ã£o (24h-7d)
- Auto-cleanup ao expirar
- MÃ³dulos especÃ­ficos permitidos
- Opcional: cadastro rÃ¡pido de voz

**Exemplo:**
```python
# Criar convidado temporÃ¡rio
POST /users/guest/create
{
  "name": "JoÃ£o (amigo)",
  "level": 2,
  "expires_at": "2025-12-04T00:00:00Z",
  "allowed_modules": ["weather", "music"]
}
```

### ğŸ”’ Re-autenticaÃ§Ã£o ContÃ­nua (Anti-EscalaÃ§Ã£o)

**Problema:** SessÃ£o iniciada por admin, outro usuÃ¡rio tenta comandos privilegiados

**SoluÃ§Ã£o:** Diarization com embeddings cadastrados re-autentica a cada comando

```yaml
Fluxo de SeguranÃ§a:
  1. Wake Word + Verification:
     - Identifica quem INICIOU sessÃ£o (embedding match)
     - Cria conversation_id
     
  2. Diarization (contÃ­nuo com embeddings):
     - Identifica quem estÃ¡ FALANDO AGORA
     - Compara embedding atual vs database cadastrado
     - Output: user_id (recognized=true) OU unknown (recognized=false)
     
  3. Conversation Manager:
     - BLOQUEIA se recognized=false (voz desconhecida)
     - Compara session_owner vs current_speaker
     - Previne escalaÃ§Ã£o de privilÃ©gios

Exemplo de Bloqueio (Voz Desconhecida):
  Admin: "ASLAM" â†’ Session: user_1 (level 10)
  Vizinho: "Desliga o alarme!"
  â†’ Diarization: embedding match 0.38 (< 0.70)
  â†’ Output: unknown_xyz, recognized=false
  â†’ Manager: IGNORA SILENCIOSAMENTE âŒ

Exemplo de Bloqueio (PermissÃ£o):
  Admin: "ASLAM" â†’ Session: user_1 (level 10)
  Esposa: "Execute script"
  â†’ Diarization: user_2, recognized=true âœ…
  â†’ Manager: level 8 < required 10 âŒ NEGADO
```

**Auditoria:**
- Flag `speaker_mismatch` e `recognized=false`
- Metadata: quem iniciou vs quem tentou

---

## ğŸ“¦ Lista Completa de Containers

### 1. **audio-bridge**
- **FunÃ§Ã£o:** Ponte entre Aslam App (tablet) e pipeline de Ã¡udio
- **Tecnologia:** Node.js + WebRTC + WebSocket
- **Responsabilidades:**
  - Receber stream de Ã¡udio do tablet via WebSocket
  - Converter WebM/Opus â†’ PCM 16kHz
  - Aplicar VAD (filtrar silÃªncio)
  - Publicar chunks no NATS
  - Enviar Ã¡udio TTS de volta para tablet
  - Gerenciar estados visuais (idle, listening, processing, speaking)
- **ComunicaÃ§Ã£o:** WebSocket (Aslam App) + NATS
- **Porta:** 3100
- **Futuro:** Suportar microfones USB pela casa

---

### 2. **audio-capture-vad**
- **FunÃ§Ã£o:** Captura contÃ­nua de Ã¡udio do microfone
- **Tecnologia:** Sounddevice, WebRTC VAD
- **Responsabilidades:**
  - Captura em frames de 10-30ms
  - Filtra silÃªncio e ruÃ­do de fundo
  - Cancelamento de eco (AEC)
  - DetecÃ§Ã£o de atividade de voz
- **ComunicaÃ§Ã£o:** ZeroMQ PUB â†’ Wake Word
- **Formato:** PCM 16kHz mono 16-bit

---

### 2. **wake-word-detector**
- **FunÃ§Ã£o:** Detecta palavra-chave "ASLAM"
- **Tecnologia:** OpenWakeWord (Open Source)
- **Responsabilidades:**
  - DetecÃ§Ã£o em tempo real
  - Baixo consumo de recursos
  - Publica evento de ativaÃ§Ã£o
  - SupressÃ£o baseada em eventos
- **ComunicaÃ§Ã£o:** 
  - Entrada: Ã¡udio do audio-capture-vad (ZeroMQ SUB)
  - SaÃ­da: evento NATS `wake_word.detected`
- **Trigger:** Inicia processamento paralelo (Verification + Whisper + Speaker ID)

---

### 3. **speaker-verification**
- **FunÃ§Ã£o:** Valida usuÃ¡rios autorizados
- **Tecnologia:** Resemblyzer ou pyannote.audio
- **Responsabilidades:**
  - Verifica se Ã© vocÃª ou sua esposa
  - Rejeita vozes desconhecidas
  - Cria embeddings de voz
- **ComunicaÃ§Ã£o:** gRPC
- **SeguranÃ§a:** Apenas vozes cadastradas podem ativar

---

### 4. **whisper-asr (STT)**
- **FunÃ§Ã£o:** Speech-to-Text em streaming
- **Tecnologia:** Whisper.cpp (otimizado ARM)
- **Responsabilidades:**
  - TranscriÃ§Ã£o em chunks de 200-300ms
  - Baixa latÃªncia
  - Streaming contÃ­nuo
  - Timestamp por chunk
- **ComunicaÃ§Ã£o:** 
  - Entrada: PCM via gRPC
  - SaÃ­da: JSON `{text, timestamp}` â†’ Core API
- **Alternativa:** Coqui STT

---

### 5. **speaker-id-diarization**
- **FunÃ§Ã£o:** Identifica QUEM estÃ¡ falando
- **Tecnologia:** pyannote.audio
- **Responsabilidades:**
  - SeparaÃ§Ã£o por falante
  - DetecÃ§Ã£o de sobreposiÃ§Ã£o de vozes
  - CriaÃ§Ã£o de embeddings por speaker
  - Metadados `{text, speaker_id, confidence}`
- **ComunicaÃ§Ã£o:** REST/gRPC streaming
- **Trigger condicional:** Se sobreposiÃ§Ã£o â†’ aciona Source Separation

---

### 6. **source-separation** (Opcional/Condicional)
- **FunÃ§Ã£o:** Separa vozes sobrepostas
- **Tecnologia:** Demucs
- **Responsabilidades:**
  - Ativado APENAS quando detecta sobreposiÃ§Ã£o
  - Separa canais por falante
  - Reenvia para STT refinado
- **ComunicaÃ§Ã£o:** gRPC
- **Nota:** NÃ£o afeta latÃªncia em conversas normais

---

### 7. **core-gateway**
- **FunÃ§Ã£o:** Gateway REST + WebSocket para Dashboard UI
- **Tecnologia:** Node.js + Express + WS
- **Responsabilidades:**
  - Expor API REST para Dashboard
  - WebSocket para updates em tempo real
  - Rate limiting por speaker_id
  - Roteamento para serviÃ§os internos
  - Health checks de containers
- **ComunicaÃ§Ã£o:** REST + WebSocket + NATS
- **Porta:** 3000

---

### 8. **conversation-manager**
- **FunÃ§Ã£o:** Gerencia estado e contexto de conversaÃ§Ãµes
- **Tecnologia:** Node.js + Prisma + Qdrant Client
- **Responsabilidades:**
  - Criar/atualizar/encerrar conversaÃ§Ãµes
  - Manter contexto por speaker_id
  - Persistir no PostgreSQL
  - Buscar contexto semÃ¢ntico (RAG) no Qdrant
  - Coordenar pipeline STT â†’ Brain â†’ TTS
- **ComunicaÃ§Ã£o:** NATS + gRPC + PostgreSQL + Qdrant

---

### 9. **action-dispatcher**
- **FunÃ§Ã£o:** Despacha comandos para outros mÃ³dulos
- **Tecnologia:** Node.js + NATS + Circuit Breaker
- **Responsabilidades:**
  - Parsear actions do Brain
  - Enviar comandos via NATS para IoT, ComunicaÃ§Ã£o, Pagamentos, etc
  - Aguardar confirmaÃ§Ãµes (request/reply)
  - Retry logic com exponential backoff
  - Circuit breaker por mÃ³dulo
- **ComunicaÃ§Ã£o:** NATS request/reply
- **IntegraÃ§Ãµes:** Todos os 8 mÃ³dulos externos

---

### 10. **mordomo-brain (LLM)**
- **FunÃ§Ã£o:** CÃ©rebro do assistente
- **Tecnologia:** 
  - **PrimÃ¡rio (Cloud):** Claude, GPT-4, Gemini, Groq via LiteLLM
  - **Fallback (Local):** Ollama (Qwen 2.5 1.5B quantizado)
- **Responsabilidades:**
  - Processamento de linguagem natural
  - ManutenÃ§Ã£o de contexto por speaker
  - DetecÃ§Ã£o de intenÃ§Ãµes
  - Roteamento de tarefas (IoT, clima, etc)
  - EstratÃ©gias LiteLLM:
    - `cloud-first` (padrÃ£o: Claude/GPT â†’ fallback 1.5B local)
    - `cloud-only` (sem fallback, mais confiÃ¡vel)
    - `local-only` (offline mode, Qwen 1.5B)
- **ComunicaÃ§Ã£o:** gRPC
- **Entrada:** `{text, speaker_id, timestamp, context}`
- **SaÃ­da:** `{response_text, speaker_id, actions[]}`

---

### 11. **tts-engine**
- **FunÃ§Ã£o:** Text-to-Speech em streaming
- **Tecnologia:** 
  - **Principal:** Piper TTS (super leve, ARM)
  - **Alternativa:** Coqui TTS
- **Responsabilidades:**
  - SÃ­ntese de voz natural
  - Streaming em chunks
  - PausÃ¡vel/interrompÃ­vel
  - Baixa latÃªncia (<500ms)
- **ComunicaÃ§Ã£o:** REST/gRPC
- **Formato:** PCM 16kHz mono â†’ alto-falante

---

## ğŸ”„ Fluxo de Dados Completo

```text
[UsuÃ¡rio fala no tablet]
         â†“
[1. audio-capture-vad] â†’ filtra ruÃ­do/silÃªncio
         â†“
[2. wake-word-detector] â†’ detecta "ASLAM"
         â†“
[3. speaker-verification] â†’ autorizado?
         â”œâ”€ NÃ£o â†’ descarta
         â””â”€ Sim â†’ continua
                 â†“
         [4. whisper-asr] â†’ transcreve em chunks
                 â†“
         [5. speaker-id-diarization] â†’ identifica falante
                 â†“
         (se sobreposiÃ§Ã£o â†’ [6. source-separation])
                 â†“
         [7. mordomo-core-api] â†’ orquestra
                 â†“
         [8. mordomo-brain] â†’ processa com LLM
                 â”‚
                 â”œâ”€â–º Qdrant (busca vetorial)
                 â”œâ”€â–º PostgreSQL (histÃ³rico)
                 â””â”€â–º NATS (eventos)
                 â†“
         [9. tts-engine] â†’ sintetiza resposta
                 â†“
         [Alto-falante] â†’ reproduz
                 â†“
         [12. dashboard-ui] â†’ mostra log
```

---

## ğŸ”— IntegraÃ§Ã£o com Outros Ecossistemas

### Infraestrutura
- **NATS:** Message broker compartilhado (substitui o antigo event-bus local)
- **Consul:** Service discovery compartilhado
- **Qdrant:** Armazena embeddings de conversas e speakers
- **PostgreSQL:** Persiste histÃ³rico, usuÃ¡rios, configuraÃ§Ãµes
- **Aslam App:** Interface tablet/web

### Monitoramento
- **Prometheus:** MÃ©tricas de latÃªncia, uso de CPU/RAM, chamadas
- **Loki:** Logs centralizados de todos containers
- **Grafana:** Dashboard visual de saÃºde do sistema
- **Promtail:** Coleta logs de todos containers

---

## âš™ï¸ ConfiguraÃ§Ã£o e Deploy

### Docker Compose
Todos os containers rodando em uma rede:
```yaml
networks:
  mordomo-net:
    driver: bridge
```

### VariÃ¡veis de Ambiente
```env
WAKE_WORD=ASLAM
LLM_MODE=cloud-first  # cloud-first | cloud-only | local-only
LLM_CLOUD_MODEL=claude-3-5-sonnet-20241022  # ou gpt-4o, gemini-2.0-flash
LLM_LOCAL_FALLBACK=qwen2.5:1.5b
CLOUD_API_KEY=sk-...
SPEAKER_VERIFICATION=enabled
MAX_SPEAKERS=2
```

### Hardware MÃ­nimo
- **RAM:** 4GB (ideal 8GB)
- **CPU:** ARM64 quad-core
- **Storage:** 32GB (modelos LLM locais)

---

## ğŸ“Š MÃ©tricas Importantes

- **LatÃªncia STT:** <300ms
- **LatÃªncia LLM:** <500ms (local) / <1s (cloud)
- **LatÃªncia TTS:** <200ms
- **LatÃªncia Total:** <1.5s (wake word â†’ primeira palavra falada)
- **PrecisÃ£o Speaker ID:** >95%
- **Uptime:** 99.9%

---

## ğŸš€ Casos de Uso

1. **Controle de Casa Inteligente**
   - "Aslam, acende a luz da sala"
   - "Aumenta o ar condicionado"

2. **Consultas Contextuais**
   - VocÃª: "Qual a temperatura?"
   - Aslam: "23Â°C"
   - VocÃª: "E na sala?" (mantÃ©m contexto)

3. **MultiusuÃ¡rio**
   - VocÃª: "Toca jazz"
   - Esposa (interrompe): "NÃ£o, toca clÃ¡ssica"
   - Aslam processa ambos pedidos separadamente

4. **InterrupÃ§Ãµes Naturais**
   - Aslam: "A previsÃ£o do tempo Ã©..."
   - VocÃª: "Espera, sÃ³ me diz de amanhÃ£"
   - Aslam: *para e responde sobre amanhÃ£*

---

## ğŸ”’ SeguranÃ§a

- âœ… **Speaker Verification:** Apenas vozes autorizadas
- âœ… **Local-first:** Dados sensÃ­veis nÃ£o saem da rede local
- âœ… **Encryption:** TLS para comunicaÃ§Ã£o externa
- âœ… **Isolamento:** Containers em rede privada

---

## ğŸ“ PrÃ³ximos Passos

- [ ] Implementar plugins para IoT (Zigbee, Matter)
- [ ] Adicionar suporte a mais idiomas
- [ ] Melhorar Source Separation com modelo mais leve
- [ ] Criar modo "silencioso" (apenas texto, sem TTS)
- [ ] IntegraÃ§Ã£o com calendÃ¡rio e lembretes

---

**DocumentaÃ§Ã£o atualizada:** 27/11/2025
